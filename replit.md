# SPK Network 2.0 - Decentralized Storage Validation System

## Overview

SPK Network 2.0 (HivePoA) is a decentralized storage validation protocol that integrates with the Hive blockchain for HBD (Hive Backed Dollar) payments. It focuses on Proof of Access (PoA), a cryptographic method to validate that storage nodes physically hold the files they claim to store. This project aims to provide a robust, decentralized storage solution with a comprehensive ecosystem for storage operators and validators. The business vision is to create a reliable and incentivized decentralized storage network, leveraging the Hive blockchain for payments and a federated trust model.

## User Preferences

Preferred communication style: Simple, everyday language.

## Project Repository

GitHub Repository: https://github.com/Dhenz14/spknetworkpoa
- Desktop agent changes should be pushed to this repository
- GitHub Actions workflow triggers on version tags (v*) for automated builds

## System Architecture

### Hybrid PWA Architecture
The system features a hybrid Progressive Web App (PWA) architecture:
-   **Browser Node (Helia)**: An in-browser IPFS node using Helia, offering no-installation usage with IndexedDB persistence.
-   **Desktop Agent (Tauri)**: A one-click desktop application (Tauri-based) that runs a 24/7 IPFS node, integrates with the system tray, and provides a local HTTP API for web app detection. It handles Hive account linking, earnings tracking, and PoA challenge responses, with auto-start on boot and native notifications.
-   **Connection Modes**: Supports Browser (Helia), Local (Kubo daemon), Remote, and Demo connections.
-   **Static Build**: The application can be built for static hosting platforms like GitHub Pages or IPFS.

### Core Features
-   **Proof of Access (PoA)**: The core innovation, providing cryptographic validation of file storage. Includes parallel block fetching, a 2-second challenge timeout, LRU block caching, batch challenges, weighted node selection, Hive block entropy for unpredictability, consecutive failure tracking, and streak bonuses.
    -   **WebSocket Validation Endpoint**: Storage nodes expose a `/validate` WebSocket endpoint to receive challenges (CID + salt) and respond with proof hashes. The validator connects directly to node endpoints for live validation.
    -   **Live Validation Mode**: When storage nodes have an `endpoint` configured, the PoA engine challenges them directly via WebSocket, verifying proof hashes against locally computed values.
    -   **PoA-Enabled Files**: Only files with `poa_enabled = true` are selected for challenges, allowing control over which content participates in validation.
-   **3Speak Integration**: Allows users to browse and pin 3Speak videos to their local IPFS node, with real-time pinning progress tracking.
-   **Storage Operator Dashboard**: Provides comprehensive tools for storage operators, including:
    -   **Earnings Dashboard**: Tracks HBD earnings, streaks, ban risks, and challenge activity.
    -   **Content Marketplace**: Recommends high-value content for pinning based on rarity and ROI.
    -   **Performance Analytics**: Monitors proofs/hour, bandwidth, success rates, and latency.
    -   **Alert System**: Notifies operators of milestones and warnings.
-   **Hive Keychain Authentication**: Secure login for validators using the Hive Keychain browser extension, restricting access to the top 150 Hive witnesses. Features server-side sessions, challenge replay protection, and protected API routes.
-   **Validator Operations Center**: Tools for validators to police the network:
    -   **Validator Dashboard**: Overview of challenge statistics, success/fail ratios, and validation earnings.
    -   **Node Monitoring**: Health map, risk assessment, and detailed drilldown for storage nodes.
    -   **Challenge Queue**: Manages pending, active, and historical challenges.
    -   **Fraud Detection**: Identifies suspicious patterns, outsourcing, collusion, and hash mismatches.
    -   **Payout Report Generator**: Validators generate payout reports from PoA data, exportable as JSON for wallet execution.
-   **Network Wallet Dashboard**: Tracks central wallet deposits, pending/executed payouts, and available balance for the storage payment system.
-   **P2P CDN Network**: Viewer-contributed bandwidth sharing system that reduces CDN costs by 50-70% through WebRTC-based peer-to-peer video segment sharing:
    -   **P2P Video Player**: HLS.js-based player with p2p-media-loader integration for seamless P2P streaming.
    -   **WebSocket Signaling**: Real-time peer coordination at `/p2p` endpoint for room management and WebRTC negotiation.
    -   **Room Management**: Automatic room creation per video CID, peer discovery, and geographic matching.
    -   **Contribution Tracking**: Tracks bytes shared, segments uploaded, session duration, and P2P ratio per viewer.
    -   **P2P Network Dashboard**: Real-time network stats, active rooms, top contributors leaderboard, and history charts.
    -   **Desktop Agent Super-Seeders**: 24/7 desktop agents act as super-seeders with existing Kubo daemon.
-   **Hybrid Encoding System**: Self-encoding capability with community fallback for video transcoding:
    -   **Desktop Agent Priority**: Uses local FFmpeg with GPU acceleration (NVENC, VAAPI, QSV) for free encoding.
    -   **Browser Fallback**: WebCodecs-based encoding for short videos (<2 min) when desktop agent unavailable. Note: Browser encoding produces video-only output suitable for previews.
    -   **Paid Encoder Marketplace**: Fixed-price community encoders sorted by reputation score (0-1000). Users select quality (1080p/720p/480p) and choose from available encoders, or submit a "name your price" custom offer and wait for encoder acceptance.
    -   **Reputation System**: Encoders earn reputation through successful jobs (+10 per 10 jobs), lose reputation for failures (-25), with success rate tracking.
    -   **Job Scheduler**: Lease-based job assignment with priority queue, retry logic with exponential backoff, and automatic expired lease cleanup.
    -   **Encoding Orchestrator**: Coordinates job lifecycle, webhook notifications with HMAC signatures, and encoder selection.
    -   **Desktop Agent Bridge API**: RESTful endpoints for desktop agents to claim/progress/complete encoding jobs.
    -   **Upload Wizard**: 4-step flow (Upload → Quality Selection → Encoder/Pricing → Review) with market price and custom offer modes.
    -   **Multi-Quality HLS**: Standard output format with 1080p/720p/480p renditions, H.264 High Profile @ Level 4.1.
    -   **Webhook Callbacks**: Real-time job status updates via webhooks to external systems with signature verification and replay protection.

### Frontend Architecture
-   **Framework**: React 18 with TypeScript
-   **Routing**: Wouter
-   **State Management**: TanStack React Query
-   **Styling**: Tailwind CSS v4 with shadcn/ui and Radix UI primitives
-   **Animations**: Framer Motion
-   **Charts**: Recharts

### Backend Architecture
-   **Framework**: Express.js with TypeScript
-   **Database**: PostgreSQL with Drizzle ORM
-   **Real-time**: WebSocket server (ws library)
-   **API Pattern**: RESTful endpoints

### Key Design Decisions
-   **Health Score Encoding**: Uses a compact Base64 encoding for health scores, based on z-scores, for efficient storage and transmission.
-   **Geographic Correction**: Adjusts latency expectations based on geographical distance to prevent unfair penalties.
-   **Federated Trust Model**: Leverages Hive's DPoS model, with the top 150 Witnesses acting as validators.
-   **HBD as Payment Rail**: Utilizes Hive Backed Dollars for all payments, avoiding custom tokens.
-   **Reputation-Based Filtering**: Implements quality tiers for storage nodes based on their reputation.

### Data Models
The system uses PostgreSQL with Drizzle ORM, organizing data into core tables for storage nodes, files, validators, PoA challenges, and Hive transactions, alongside specific tables for CDN, transcoding, moderation, encryption, reward allocation, P2P CDN features (p2p_sessions, p2p_contributions, p2p_rooms, p2p_network_stats), and hybrid encoding (encoding_jobs, encoding_profiles, user_encoding_settings, encoder_nodes) across different development phases.

### API Routes
A comprehensive set of API routes manages various functionalities including IPFS gateway, CDN, uploads, contracts, transcoding, moderation, encryption, user settings, beneficiaries, 3Speak integration, P2P CDN stats/contributions (`/api/p2p/*`), and hybrid encoding (`/api/encoding/*`).

## External Dependencies

### Database
-   PostgreSQL with Drizzle ORM

### Blockchain
-   `@hiveio/dhive` for Hive blockchain integration

### Frontend Libraries
-   React, TanStack Query, Radix UI, Framer Motion, Recharts, Lucide

### Build Tools
-   Vite, esbuild, tsx